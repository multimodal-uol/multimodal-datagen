{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SPLUNK_HOME'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a1f9ec05b031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msearchtweets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_credentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_rule_payload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResultStream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0msplunkhome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SPLUNK_HOME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplunkhome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'etc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'apps'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'searchcommands_app'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msplunklib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchcommands\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mGeneratingCommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfiguration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SPLUNK_HOME'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "#\n",
    "# Copyright Â© 2011-2015 Splunk, Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"): you may\n",
    "# not use this file except in compliance with the License. You may obtain\n",
    "# a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n",
    "# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n",
    "# License for the specific language governing permissions and limitations\n",
    "# under the License.\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import time, os\n",
    "import json\n",
    "import codecs\n",
    "from itertools import islice\n",
    "import sys, time\n",
    "import yaml\n",
    "from searchtweets import load_credentials, gen_rule_payload, ResultStream\n",
    "\n",
    "splunkhome = os.environ['SPLUNK_HOME']\n",
    "sys.path.append(os.path.join(splunkhome, 'etc', 'apps', 'searchcommands_app', 'lib'))\n",
    "from splunklib.searchcommands import dispatch,  GeneratingCommand, Configuration, Option, validators\n",
    "from splunklib import six\n",
    "\n",
    "# Define details of our account \n",
    "API_KEY = 'VzihIPxv5oFrd3SkNuBuQk9o3'\n",
    "API_SECRET_KEY = 'Iq7hi4K1cZnzgD3RC1miTM6rcrHMA4aeHj3OeCsI9OvFVtX5Ej'\n",
    "DEV_ENVIRONMENT_LABEL = 'datacollection'\n",
    "API_SCOPE = 'fullarchive'  # 'fullarchive' for full archive, '30day' for last 31 days\n",
    "RESULTS_PER_CALL = 500  # 100 for sandbox, 500 for paid tiers\n",
    "\n",
    "\n",
    "\n",
    "@Configuration()\n",
    "class Echo(GeneratingCommand):\n",
    "    testing = Option(\n",
    "        doc='''\n",
    "        **Syntax:** ***sourceindex=covid/newspaper\n",
    "        **Description:** testing or production data''',\n",
    "        require=True)\n",
    "    user = Option(\n",
    "        doc='''\n",
    "        **Syntax:** ***\n",
    "        **Description:**''',\n",
    "        require=False)    \n",
    "    word = Option(\n",
    "        doc='''\n",
    "        **Syntax:** ***\n",
    "        **Description:**''',\n",
    "        require=False)\n",
    "    bd = Option(\n",
    "        doc='''\n",
    "        **Syntax:** ***\n",
    "        **Description:**''',\n",
    "        require=False)\n",
    "    ed = Option(\n",
    "        doc='''\n",
    "        **Syntax:** ***\n",
    "        **Description:**''',\n",
    "        require=False)\n",
    "    location = Option(\n",
    "        doc='''\n",
    "        **Syntax:** ***\n",
    "        **Description:**''',\n",
    "        require=False)\n",
    "    limit = Option(\n",
    "        doc='''\n",
    "        **Syntax:** ***\n",
    "        **Description:**''',\n",
    "        require=False)\n",
    "    userName = Option(\n",
    "        doc='''\n",
    "        **Syntax:** ***\n",
    "        **Description:**''',\n",
    "        require=False)\n",
    "    testing = Option(\n",
    "        doc='''\n",
    "        **Syntax:** ***\n",
    "        **Description:**''',\n",
    "        require=False)\n",
    "           \n",
    "\n",
    "    def generate(self):\n",
    "        config = dict(\n",
    "                search_tweets_api=dict(\n",
    "                    account_type='premium',\n",
    "                    endpoint=f\"https://api.twitter.com/1.1/tweets/search/fullarchive/datacollection.json\",\n",
    "                    consumer_key=API_KEY,\n",
    "                    consumer_secret=API_SECRET_KEY\n",
    "                )\n",
    "            )\n",
    "        with open('twitter_keys.yaml', 'w') as config_file:\n",
    "            yaml.dump(config, config_file, default_flow_style=False)\n",
    "        premium_search_args = load_credentials(\"twitter_keys.yaml\",yaml_key=\"search_tweets_api\",env_overwrite=False)\n",
    "        if str(self.word) != 'null' or str(self.user) != 'null':\n",
    "            timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "            if (self.userName =='-anonymous'):\n",
    "                self.userName = ''\n",
    "                \n",
    "      \n",
    "            if (self.user !='null'):\n",
    "                searchID = self.user+timestr[10:]+self.userName\n",
    "                tmpoutputfile = '/tmp/'+searchID+'.json' \n",
    "                cmd1 = ('/opt/anaconda3/bin/python3.7' \n",
    "                        +' /opt/splunk/etc/apps/multimodal-datagen/bin/twittercrawler.py  '\n",
    "                        + self.bd +' '+self.ed + ' '+ tmpoutputfile + ' '+'null'\n",
    "                        + ' '+self.location + ' '+ self.user + ' '+ self.limit)\n",
    "                f = open(\"/tmp/commands.txt\", \"w\")\n",
    "                f.write(str(cmd1))\n",
    "                f.close()     \n",
    "                os.system(cmd1)\n",
    "                #x= subprocess.check_output(cmd1, shell=True)\n",
    "                \n",
    "                if self.testing =='True':\n",
    "                    outputfile='/tmp/'+searchID\n",
    "                else:\n",
    "                    outputfile='/opt/twitterdata/tweets/'+searchID\n",
    "                           \n",
    "\n",
    "            elif (self.word !='null'):\n",
    "                searchID = self.word+timestr[10:]+self.userName\n",
    "                tmpoutputfile = '/tmp/'+searchID+time.strftime(\"%Y%m%d-%H%M%S\")+'.json'\n",
    "                self.word  = self.word.replace(\"SPACE\", \" \")\n",
    "                \n",
    "                FROM_DATE = seld.bd + '00:00'\n",
    "                TO_DATE = self.ed + '00:00'\n",
    "                # Put together search terms and rules from earlier\n",
    "                rule = gen_rule_payload(self.word,\n",
    "                                        results_per_call=RESULTS_PER_CALL,\n",
    "                                        from_date=FROM_DATE,\n",
    "                                        to_date=TO_DATE\n",
    "                                        )\n",
    "\n",
    "                # Stream tweets rather than download in one go\n",
    "                rs = ResultStream(rule_payload=rule,\n",
    "                                  max_results=self.limit,\n",
    "                                  **premium_search_args)\n",
    "\n",
    "                # Access API and save each tweet as single line on JSON lines file\n",
    "                with open(tmpoutputfile, 'a', encoding='utf-8') as f:\n",
    "                    for tweet in rs.stream():\n",
    "                        json.dump(tweet, f)\n",
    "                        f.write('\\n')\n",
    "\n",
    "                \n",
    "                if self.testing =='True':\n",
    "                    outputfile='/tmp/'+searchID+time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "                else:\n",
    "                    outputfile='/tmp/'+searchID\n",
    "                    \n",
    "            if  os.path.exists(tmpoutputfile):\n",
    "                yield{'Message':'Success'}\n",
    "                \n",
    "            else:\n",
    "                yield{'Message':'No Results Found!'}\n",
    "                return\n",
    "        else:\n",
    "            yield{'Message' : \"Enter Input in the Textboxes \"}\n",
    "            return;\n",
    "                    \n",
    "            \n",
    "                    \n",
    "\n",
    "            \n",
    "dispatch(Echo, sys.argv, sys.stdin, sys.stdout, __name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
